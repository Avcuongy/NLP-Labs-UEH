{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a721c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213ce40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = \"Xin chào tất cả mọi ngưoời. Hôm nay chúng ta sẽ học về xử lý ngôn ngữ tự nhiên\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5450f6c6",
   "metadata": {},
   "source": [
    "# Thay đổi vector biểu diễn dưới dạng\n",
    "\n",
    "```\n",
    "{'contains(waste)':False, 'contains(lot)': False, ... }\n",
    "```\n",
    "\n",
    "```\n",
    "{'waste':10, 'lot': 5, ...} Từ - Tấn số\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b2bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_words_from_document(doc):\n",
    "    \"\"\"\n",
    "    Trích danh sách từ (lowercase) từ một document. doc có thể là (list_tu, nhãn), hoặc list_tu, hoặc string.\n",
    "    \"\"\"\n",
    "    # Nếu là tuple (words, label)\n",
    "    if isinstance(doc, tuple) and len(doc) >= 1:\n",
    "        doc = doc[0]\n",
    "    if isinstance(doc, list):\n",
    "        words = [str(w).lower() for w in doc]\n",
    "    elif isinstance(doc, str):\n",
    "        # Tokenize đơn giản cho tiếng Việt/Anh (giữ chữ/số)\n",
    "        words = re.findall(r\"\\w+\", doc.lower())\n",
    "    else:\n",
    "        words = []\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3fa9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean contains(word) và đếm tần suất\n",
    "tokens = doc_words_from_document(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b97c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count features: {'waste': 10, 'lot': 5, ...}\n",
    "# Chỉ tạo đặc trưng đếm tại đây; đặc trưng boolean sẽ tạo sau khi xác định vocab\n",
    "features_counts = dict(Counter(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333e50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary và đặc trưng boolean\n",
    "vocab = sorted(set(tokens))\n",
    "features_contains = {f\"contains({w})\": (w in set(tokens)) for w in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3b6e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số từ trong tài liệu mẫu: 19\n",
      "Kích thước vocab: 19\n",
      "Số đặc trưng dạng boolean: 19\n",
      "Số đặc trưng dạng đếm: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Số từ trong tài liệu mẫu: {len(tokens)}\")\n",
    "print(f\"Kích thước vocab: {len(vocab)}\")\n",
    "print(f\"Số đặc trưng dạng boolean: {len(features_contains)}\")\n",
    "print(f\"Số đặc trưng dạng đếm: {len(features_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea3f0ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một vài đặc trưng boolean:\n",
      "\"contains(chào)\": True\n",
      "\"contains(chúng)\": True\n",
      "\"contains(cả)\": True\n",
      "\"contains(hôm)\": True\n",
      "\"contains(học)\": True\n",
      "\n",
      "Một vài đặc trưng đếm:\n",
      "\"xin\": 1\n",
      "\"chào\": 1\n",
      "\"tất\": 1\n",
      "\"cả\": 1\n",
      "\"mọi\": 1\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị một vài phần tử mẫu\n",
    "print(\"Một vài đặc trưng boolean:\")\n",
    "for k, v in itertools.islice(features_contains.items(), 5):\n",
    "    print(f\"\\\"{k}\\\": {v}\")\n",
    "\n",
    "print(\"\\nMột vài đặc trưng đếm:\")\n",
    "for k, v in itertools.islice(features_counts.items(), 5):\n",
    "    print(f\"\\\"{k}\\\": {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31826b18",
   "metadata": {},
   "source": [
    "# Xây dựng hạng biểu diễn encode dạng vector trong sklearn\n",
    "\n",
    "```\n",
    "Vocab{waste, lot, many} --> (?, ?, ?)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e3b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Encode dạng vector trong sklearn (CountVectorizer)\n",
    "# Hàm chuyển document về chuỗi (nếu đầu vào là tokens)\n",
    "def doc_to_text(doc):\n",
    "    words = doc_words_from_document(doc)\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Xây dựng corpus văn bản\n",
    "if isinstance(documents, list):\n",
    "    corpus_texts = [doc_to_text(d) for d in documents[:200]]  # dùng 200 tài liệu đầu\n",
    "elif isinstance(documents, str):\n",
    "    corpus_texts = [doc_to_text(documents)]\n",
    "else:\n",
    "    corpus_texts = [\n",
    "        \"Khi bão đổ bộ sóng gió nổi lên\",\n",
    "        \"Khi bão đổ bộ xóng gió nổi lên\",\n",
    "        \"Bão lớn gây mưa to gió mạnh\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Xây dựng vocabulary\n",
    "# Lấy vocab từ chính corpus\n",
    "tokens_all = []\n",
    "for t in corpus_texts:\n",
    "    tokens_all.extend(re.findall(r\"\\w+\", t.lower()))\n",
    "vocab_for_vectorizer = sorted(set(tokens_all))\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_for_vectorizer, lowercase=True, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vectorizer.transform(corpus_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed8a24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước vocab: 19\n",
      "Kích thước ma trận (số văn bản, số đặc trưng): (1, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Kích thước vocab:\", len(vectorizer.vocabulary_))\n",
    "print(\"Kích thước ma trận (số văn bản, số đặc trưng):\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3146a474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đặc trưng khác 0 của văn bản [0]: [('chào', 1), ('chúng', 1), ('cả', 1), ('hôm', 1), ('học', 1), ('lý', 1), ('mọi', 1), ('nay', 1), ('ngôn', 1), ('ngưoời', 1), ('ngữ', 1), ('nhiên', 1), ('sẽ', 1), ('ta', 1), ('tất', 1), ('tự', 1), ('về', 1), ('xin', 1), ('xử', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Xem vector của văn bản đầu tiên\n",
    "first_vec = X[0].toarray()[0]\n",
    "\n",
    "# Lấy các đặc trưng khác 0 để quan sát\n",
    "inv_vocab = {idx: term for term, idx in vectorizer.vocabulary_.items()}\n",
    "non_zero = [(inv_vocab[i], int(c)) for i, c in enumerate(first_vec) if c > 0]\n",
    "print(\"Đặc trưng khác 0 của văn bản [0]:\", non_zero[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
